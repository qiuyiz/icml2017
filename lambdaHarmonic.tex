
\section{Realizable Potentials with Convergence Guarantees}
\label{sec:almost-harmonic}
{\color{red} 
Under some assumptions, we
will show that gradient descent can learn at least one of the $w_i's$
of the target network for certain activation functions. The algorithm
will try to learn a guess
$\widetilde{f}(x_j) = \sum_{i=1}^k a_i \sigma(x_j,\theta_i)$ for $f$
and then running gradient descent over the parameters $a_i, \theta_i$
will move them to $b_i, w_i$. We will prove that at convergence, at
least one $\theta_i$ is equal to (or close to) some $w_j$. Note that
we may end up with a many to one mapping of the learned hidden weights
to the true hidden weights, instead of a bijection.


% Next, we provide a partial theoretical justification for this phenomena with simplifying assumptions.
}
%
In this section, we derive convergence guarantees for a class of realizable potentials that closely approximate $\lambda$-harmonic potentials. First, we construct realizable potentials with corresponding activation functions that are almost $\lambda$-harmonic, specifically they are $\lambda$-harmonic outside of a small neighborhood around the center. Then, we reason similarly about the Laplacian of our loss function to derive our convergence theorem. To make sure that $\|a\|$ remains controlled throughout the optimization process, we add a quadratic regularization term to $L$ and instead run our optimization procedure on $G = L + \|a\|^2$.

Our optimization procedure is a slightly altered version of gradient descent, where we incorportate a second-order method (which we named Hessian descent as in Algorithm~\ref{HD}) are used when the gradient is too small and progress is slow. The descent algorithm (Algorithm~\ref{SecondGD}) allows us to converge to points with small gradient and small negative curvature. Namely, in $\poly(1/\epsilon)$ iterations, we should have reached a point in $\mathcal{M}_{G, \epsilon}$, where 
%
%
\begin{align*}
\mathcal{M}_{G, \epsilon} = \left\{x\in \mathcal{M} \Big| \|\nabla G(x)\|
  \leq \epsilon \text{ and } \lambda_{min}(\nabla^2 G(x)) \geq
  -\epsilon\right\}
  \end{align*}
  %
Then, we show that if $(\boldsymbol{a,\theta})$ is in $\mathcal{M}_{G, \epsilon}$ for $\epsilon$ small, then $\theta_i$ is close to $w_j$ for some $j$. Finally, we show how to initialize $(\boldsymbol{a^{(0)},\theta^{(0)}})$ and run second-order GD to converge to $\mathcal{M}_{G,\epsilon}$, proving our main theorem.

\Snote{The use of second-order methods is not limiting since noisy gradient descent algorithms can descent along negative curvature directions. Therefore, stochastic gradient descent should also converge to $M_{G,\epsilon}$ \cite{GeHJY15}, although we lack some regularity conditions. Furthermore, a more controlled perturbed gradient descent \cite{jin2017escape} can be applied in our setting to reach $M_{G,\epsilon}$ but requires more in-depth analysis.}
%\Snote{Fix name of Hessian descent}
%
\alglanguage{pseudocode}
\begin{algorithm}[hb]
 \caption{$x = HD(L,x_0, T,\alpha$)}
   \label{HD}
\begin{algorithmic}
   \State {\bfseries Input:} $L: \mathcal{M} \to \R$; $x_0 \in \mathcal{M}$; $T\in \N$; $\alpha \in \R$
   \State Initialize $x = x_0$
   \For {$i=1$ {\bfseries to} $T$}
   \State Find unit eigenvector $v_{min}$ corresponding to $\lambda_{min}(\nabla^2 f(x))$ 
   \State  $\beta = -\alpha \lambda_{min}(\nabla^2 f(x)) \sign(\nabla f(x)^Tv_{min}) $
    \State $x = x + \beta v_{min}$
   \EndFor
\end{algorithmic}
\end{algorithm}
%
\begin{algorithm}[hb]
 \caption{$x = SecondGD(L, x_0, T,\alpha, \eta, \gamma)$}
   \label{SecondGD}
\begin{algorithmic}
   \State {\bfseries Input:} $L:\mathcal{M} \to \R$; $x_0 \in
   \mathcal{M}$; $T\in \N$; $\alpha, \eta, \gamma \in \R$
%\Snote{Fix $\alpha$ vs $\gamma$}
   \For {$i=1$ {\bfseries to} $T$}
   \If {$\|\nabla L(x_{i-1})\| \geq  \eta$}\  $x_{i} = GD(L, x_{i-1}, 1, \alpha)$
   \Else \
$x_i = HD(L, x_{i-1}, 1, \alpha)$ 
  \EndIf
   \If {$ L(x_i) \geq L(x_{i-1}) - min(\alpha\eta^2/2, \alpha^2 \gamma^3/2) $}
     \Return $x_{i-1}$
   \EndIf 
% \Snote{I think you can merge the two returns. Just move along the smallest eigenvalue direction, if loss decrement is small, return the previous point.}
   \EndFor
   \end{algorithmic}
%
\end{algorithm}
\begin{algorithm}[hb]
 \caption{$x = GD(L,x_0, T,\alpha$)}
   \label{GD}
\begin{algorithmic}
   \State {\bfseries Input:} $L: \mathcal{M} \to \R$; $x_0 \in \mathcal{M}$; $T\in \N$; $\alpha\in \R$
   \State Initialize $x = x_0$
   \For {$i=1$ {\bfseries to} $T$}
   \State $x = x - \alpha\nabla L(x)$
   \State $x = \Pi_\mathcal{M} x$
   \EndFor
\end{algorithmic}
\end{algorithm}
%
%
\begin{theorem}\label{almostHarmSGD}
  Let $\mathcal{M} = \R^{d}$ for $d \equiv 3 \mod 4$ and $k = \poly(d)$. For all $\epsilon \in (0,1),$ we can construct an activation $\sigma_\epsilon$ such that if $w_1,...,w_k \in \R^d$ with $w_i$ randomly chosen from $w_i \sim  \mathcal{N}({\bf 0}, O(d\log d){\bf I_{d\times d}})$ and $b_1,...,b_k$ be randomly chosen at uniform from $[-1,1]$, then with high probability, we can choose an initial point $(\boldsymbol{a^{(0)}, \theta^{(0)}})$ such that after running SecondGD (Algorithm \ref{SecondGD}) on the regularized objective $G(\boldsymbol{a,\theta})$ for at most $(d/\epsilon)^{O(d)}$ iterations, there exists an $i, j$ such that $\|\theta_i - w_j\| <  \epsilon$.
\end{theorem}
%
We start by stating a lemma concerning the construction of an almost
$\lambda$-harmonic function on $\R^d.$ The construction is given in the appendix and uses a linear combination of realizable potentials that correspond to an activation function of the indicator function of a $n$-sphere. By using Fourier analysis and Theorem~\ref{thm:tranReal}, we can finish the construction of our almost $\lambda$-harmonic potential.%
%
\begin{restatable}{lemma}{almostharmreal}
\label{almostHarmReal}
Let $\mathcal{M} = \R^d$ for $d \equiv 3 \mod 4$. Then, for any $1 > \epsilon > 0$, we can construct a radial activation $\sigma_\epsilon(r)$ with corresponding normalized radial potential $\Phi_\epsilon(r)$ that is $\lambda$-harmonic when $r \geq \epsilon$.

Furthermore, we have ${\Phi_\epsilon}^{(d-1)}(r) \geq 0$ for all $r  > 0$ and ${\Phi_\epsilon}^{(k)}(r) \geq 0$ and ${\Phi_\epsilon}^{(k+1)}(r)\leq 0$ for all $r > 0$ and $d - 3 \geq k \geq 0 $ even.

Lastly, $|{\Phi}_\epsilon^{(k)}(r)| \leq 3(2d + \sqrt{\lambda})^{2d} \epsilon^{-2d}e^{\sqrt{\lambda}}$ for all $0 \leq k \leq d-1$. And for $r \geq \epsilon$, $e^{-\sqrt{\lambda}r}r^{2-d}(2d+\sqrt{\lambda})^{-2d}\epsilon^{2d}/3\leq {\Phi}_\epsilon(r) \leq (1+r\sqrt{\lambda})^de^{\sqrt{\lambda}(1-r)}(r)^{2-d}$. Also for $r \geq \epsilon$, $ e^{-\sqrt{\lambda}r}r^{1-d}(2d+\sqrt{\lambda})^{-2d}\epsilon^{2d}/3 \leq |{\Phi}_\epsilon'(r)| \leq (d+\sqrt{\lambda}r)(1+ r\sqrt{\lambda})^de^{\sqrt{\lambda}(1- r)} r^{1-d}$
\end{restatable}
%
%
Our next lemma use the almost $\lambda$-harmonic properties to show that at an almost stationary point of $G$, we must have converged close to some $w_j$ as long as our charges $a_i$ are not too small. The proof is similar to Theorem \ref{EigStrict}. Then, the following lemma relates the magnitude of the charges $a_i$ to the progress made in the objective function. 
%\Snote{Expand this statement, and refer to the theorem below. Interpret that it is an approximate version of the previous exact theorem.}
%
\begin{restatable}{lemma}{almostharmconv}\label{almostHarmConv}
Let $\mathcal{M} = \R^d$ for $d \equiv 3 \mod 4$ and let $G$ be the regularized loss corresponding to the activation function $\sigma_\epsilon$ given by Lemma~\ref{almostHarmReal} with $\lambda =1$. For any $\epsilon \in (0,1)$ and $\delta \in (0, 1)$, if $\boldsymbol{(a,\theta)} \in \mathcal{M}_{G,\delta}$, then for all $i$, either 1) there exists $j$ such that $\|\theta_i - w_j\| < k\epsilon$ or 2) $a_i^2 < 2kd\delta$.
\end{restatable}
%
\begin{restatable}{lemma}{almostharmres}\label{almostHarmRes}
  Assume the conditions of Lemma~\ref{almostHarmConv}. If
$\sqrt{G({\bf a, \boldsymbol{\theta}})} \leq \sqrt{G(\boldsymbol{0,0})} - \delta$
  and $(\boldsymbol{a,\theta}) \in \mathcal{M}_{G,\delta^2/(2k^3d)}$,
  then there exists some $i, j$ such that $\|\theta_i - w_j\| <k\epsilon$.
\end{restatable}
 %
 Finally, we guarantee that our initialization substantially decreases our objective function. Together with our previous lemmas, it will imply that we must be close to some $w_j$ upon convergence. This is the overview of the proof of Theorem~\ref{almostHarmSGD}, presented below.
 %
 \begin{restatable}{lemma}{almostharminitialize}[Initialization]\label{almostHarmInitialize}
Assume the conditions of Theorem~\ref{almostHarmSGD} and Lemma~\ref{almostHarmConv}. With high probability, we can initialize $\boldsymbol{(a^{(0)},\theta^{(0)})}$ such that $\sqrt{G({\bf a^{(0)}}, \boldsymbol{\theta^{(0)}})} \leq \sqrt{G(\boldsymbol{0,0})} -\delta$ with $\delta = (d/\epsilon)^{ - O(d)}$.
 \end{restatable}
 %
\begin{proof}[Proof of Theorem \ref{almostHarmSGD}]
% \Snote{Richard: I don't think you have updated the theorem below using the changes in the previous lemmas. E.g. the incorrect initialization condition is used here. Please make sure it's all consistent with the updated lemmas.}
  Let our potential $\Phi_{\epsilon/k}$ be the one as constructed in Lemma~\ref{almostHarmReal} that is $1$-harmonic for all $r \geq \epsilon/k$ and as always, $k = \poly(d)$.  First, by Lemma~\ref{almostHarmInitialize}, we can initialize $\boldsymbol{(a^{(0)},\theta^{(0)})}$ such that $\sqrt{G(\boldsymbol{a^{(0)},\theta^{(0)}})} \leq \sqrt{G({\bf 0,0})} - \delta$ for $\delta = (d/\epsilon)^{-O(d)}$. If we set $\alpha = (d/\epsilon)^{-O(d)}$ and $\eta = \gamma = \delta^2/(2k^3d)$, then running Algorithm~\ref{SecondGD} will terminate and return some $(\boldsymbol{a,\theta})$ in at most $(d/\epsilon)^{O(d)}$ iterations. This is because our algorithm ensures that our objective function decreases by at least $\min(\alpha \eta^2/2, \alpha^2\gamma^3/2)$ at each iteration, $G({\bf 0, 0})$ is bounded by $O(k),$ and $G \geq 0$ is non-negative.

Let $\boldsymbol{\theta} = (\theta_1,...\theta_k)$. If there exists $\theta_i, w_j$ such that $\|\theta_i - w_j\| < \epsilon$, then we are done. Otherwise, we claim that $(\boldsymbol{a,\theta}) \in \mathcal{M}_{G, \delta^2/(2k^3d)}$. For the sake of contradiction, assume otherwise. By our algorithm termination conditions, then it must be that after one step of gradient or Hessian descent from $(\boldsymbol{a,\theta})$, we reach some $(\boldsymbol{a',\theta'})$ and $G(\boldsymbol{a',\theta'}) > G(\boldsymbol{a,\theta}) - \min(\alpha\eta^2/2,\alpha^2\gamma^3/2)$.

Now, Lemma~\ref{almostHarmReal} ensures all first three derivatives of $\Phi_{\epsilon/k}$ are bounded by $O((dk/\epsilon)^{2d})$, except at $w_1,...,w_k$. Furthermore, since there does not exists $\theta_i, w_j$ such that $\|\theta_i - w_j\| <\epsilon$, $G$ is three-times continuously differentiable within a $\alpha (dk/\epsilon)^{2d} = (d/\epsilon)^{-O(d)}$ neighborhood of $\boldsymbol{\theta}$. Therefore, by Lemma~\ref{GradDecrease} and ~\ref{HessianDecrease}, we must have  we know that $G(\boldsymbol{a',\theta'}) \leq G(\boldsymbol{a,\theta}) - \min(\alpha\eta^2/2,\alpha^2\gamma^3/2)$. a contradiction. Lastly, since our algorithm maintains that our objective function is decreasing, so $\sqrt{G(\boldsymbol{a,\theta})} \leq \sqrt{G({\bf 0,0})} - \delta$. Finally, we conclude by Lemma \ref{almostHarmRes}.
\end{proof}

\subsection{Node-by-Node Analysis}
We cannot easily analyze the convergence of gradient descent to the global minima when all $\theta_i$ are simultaneously moving since the pairwise interaction terms between the $\theta_i$ present complications, even with added regularization. Instead, we run a greedy
node-wise descent \Snote{Use the correct algorithm name} algorithm to learn the hidden weights, i.e. we run a descent algorithm with respect to $(a_i,\theta_i)$ sequentially. The
main idea is that after running SGD with respect to $\theta_1$,
$\theta_1$ should be close to some $w_j$ for some $j$. Then, we can
carefully induct and show that $\theta_2$ must be some other $w_k$ for
$k\neq j$ and so on.

%
\begin{algorithm}[tb]
 \caption{Node-wise Descent Algorithm with Output Weights Optimization}
   \label{NodeGDOpt}
\begin{algorithmic}
  \State {\bfseries Input:}
  $(\boldsymbol{a,\theta}) = (a_1,...,a_k,\theta_1,...,\theta_k), a_i
  \in\R, \theta_i\in\mathcal{M}$;
  $T\in \N$; $L$; $\alpha, \eta, \gamma \in \R$; 
  \For {$i=1$ {\bfseries to} $k$} 
  \State{\bf Initialize} $(a_i, \theta_i)$
  \State $(a_i, \theta_i) = SecondGD \left(L_{a_i, \theta_i},(a_i,\theta_i),T, \alpha,\eta,\gamma \right)$
   \EndFor
   \State {\bf return} $a = (a_1,...,a_k), \theta = (\theta_1,..., \theta_k)$
   \end{algorithmic}
\end{algorithm}

Let $L_1(a_1,\theta_1)$ be the objective $L$ restricted to $a_1,\theta_1$ being variable, and $a_2,...,a_k = 0$ are fixed. The tighter control on the movements of $\theta_1$ allows us to remove our regularization. While our previous guarantees before allow us to reach a $\epsilon$-neighborhood of $w_j$ when running SGD on $L_1$, we will strengthen our guarantees to reach a $(d/\epsilon)^{-O(d)}$-neighborhood of $w_j$, by reasoning about the first derivatives of our potential in an $\epsilon$-neighborhood of $w_j$. By similar argumentation as before, we will be able to derive the following convergence guarantees for node-wise training. 

\begin{restatable}{theorem}{nodewise}\label{nodeWise}
Let $\mathcal{M} = \R^{d}$ and $d \equiv 3 \mod 4$ and let $L$ be as in \ref{errLoss} and $k = \poly(d)$. For all $\epsilon \in (0,1),$ we can construct an activation $\sigma_\epsilon$ such that if $w_1,...,w_k \in \R^d$ with $w_i$ randomly chosen from $w_i \sim  \mathcal{N}({\bf 0}, O(d\log k){\bf I_{d\times d}})$ and $b_1,...,b_k$ be randomly chosen at uniform from $[-1,1]$, then with high probability, after running nodewise descent (Algorithm \ref{NodeGDOpt}) on the objective $L$ for at most $(d/\epsilon)^{O(d)}$ iterations, $\boldsymbol{(a,\theta)}$ is in a $(d/\epsilon)^{-O(d)}$ neighborhood of the global minima.
\end{restatable}

%
%%
%\begin{algorithm}[hb]
% \caption{$x = NoisyGD(\widehat{L}, x_0, T,\alpha,\epsilon)$}
%   \label{SGD}
%\begin{algorithmic}
%   \STATE {\bfseries Input:} $\widehat{L}:\mathcal{M} \to \R$; $x_0 \in \mathcal{M}$; $T\in \N$; $\alpha \in \R$; $\epsilon\in\R$
%   \vspace{.1in}
%   \STATE {\bf Initialize} $x = x_0$
%   \WHILE{{\it true}}
%   \STATE $x_1 = x$
%   \FOR{$i=1$ {\bfseries to} $T$}
%   \STATE Sample $\omega$ uniformly on unit sphere.
%   \STATE $x_{i+1} = x_i - \alpha(\nabla \widehat{L} (x_i)+\alpha\omega)$ 
%%\STATE $x = \Pi_\mathcal{M} x$
%   \ENDFOR
%    \IF{$\widehat{L}(x_i) - \widehat{L}(x) < \alpha^2$ for all $i$}
%   \STATE {\bf return} $x$
%   \ELSE 
%   \STATE Find $i$ such that $\widehat{L}(x_i) - \widehat{L}(x) \geq \alpha^2$ 
%   \STATE $x = x_i$
%   \ENDIF
%   \ENDWHILE
%\end{algorithmic}
%\end{algorithm}
%%

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "icmlpaper2017.tex"
%%% End: